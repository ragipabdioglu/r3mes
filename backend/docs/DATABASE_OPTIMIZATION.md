# Database Optimization Guide

This document outlines the database optimization strategy for R3MES backend, including index management, query optimization, and migration procedures.

## 1. Index Strategy

### 1.1. SQLite Indexes

SQLite uses B-tree indexes for efficient lookups. The following indexes are automatically created:

**Users Table:**
- `idx_users_is_miner`: For filtering miners
- `idx_users_created_at`: For time-based queries

**Mining Stats Table:**
- `idx_mining_stats_wallet`: For filtering by wallet address
- `idx_mining_stats_recorded_at`: For time-based queries
- `idx_mining_stats_wallet_recorded`: Composite index for wallet + time queries

**Earnings History Table:**
- `idx_earnings_history_wallet`: For filtering by wallet address
- `idx_earnings_history_recorded_at`: For time-based queries
- `idx_earnings_history_wallet_recorded`: Composite index for wallet + time queries

**Hashrate History Table:**
- `idx_hashrate_history_wallet`: For filtering by wallet address
- `idx_hashrate_history_recorded_at`: For time-based queries
- `idx_hashrate_history_wallet_recorded`: Composite index for wallet + time queries

**API Keys Table:**
- `idx_api_key_hash`: Unique index for API key lookups (already exists)
- `idx_api_keys_wallet`: For filtering by wallet address
- `idx_api_keys_is_active`: For filtering active keys
- `idx_api_keys_expires_at`: For filtering expired keys

### 1.2. PostgreSQL Indexes

PostgreSQL uses more advanced indexing strategies:

**Composite Indexes with DESC:**
- `idx_mining_stats_wallet_recorded`: `(wallet_address, recorded_at DESC)` for efficient time-based queries
- `idx_earnings_history_wallet_recorded`: `(wallet_address, recorded_at DESC)`
- `idx_hashrate_history_wallet_recorded`: `(wallet_address, recorded_at DESC)`

**Partial Indexes:**
- `idx_api_keys_wallet_active`: `(wallet_address, is_active) WHERE is_active = TRUE` - Only indexes active keys

**Blockchain Events Indexes:**
- `idx_blockchain_events_type_height`: `(event_type, block_height DESC)` for filtered range queries
- `idx_blockchain_events_miner_height`: `(miner_address, block_height DESC) WHERE miner_address IS NOT NULL`
- `idx_blockchain_events_height_indexed`: `(block_height DESC, indexed_at DESC)` for range queries

## 2. Query Optimization

### 2.1. Best Practices

1. **Use LIMIT**: Always use LIMIT for queries that return large result sets
2. **Index Usage**: Ensure WHERE clauses use indexed columns
3. **Avoid SELECT \***: Select only needed columns
4. **Use EXPLAIN**: Use EXPLAIN QUERY PLAN (SQLite) or EXPLAIN (PostgreSQL) to analyze query performance

### 2.2. Optimized Query Patterns

**Earnings History Query:**
```sql
SELECT DATE(recorded_at) as date, SUM(earnings) as total_earnings
FROM earnings_history
WHERE wallet_address = ? 
AND recorded_at >= datetime('now', '-' || ? || ' days')
GROUP BY DATE(recorded_at)
ORDER BY date ASC
```
Uses: `idx_earnings_history_wallet_recorded`

**Hashrate History Query:**
```sql
SELECT DATE(recorded_at) as date, AVG(hashrate) as avg_hashrate
FROM hashrate_history
WHERE wallet_address = ? 
AND recorded_at >= datetime('now', '-' || ? || ' days')
GROUP BY DATE(recorded_at)
ORDER BY date ASC
```
Uses: `idx_hashrate_history_wallet_recorded`

**Mining Stats Query:**
```sql
SELECT hashrate, gpu_temperature, blocks_found, uptime_percentage, network_difficulty, recorded_at
FROM mining_stats
WHERE wallet_address = ?
ORDER BY recorded_at DESC
LIMIT 10
```
Uses: `idx_mining_stats_wallet_recorded`

## 3. Migration Strategy

### 3.1. Alembic Setup

The project uses Alembic for database migrations:

```bash
# Initialize Alembic (already done)
alembic init alembic

# Create a new migration
alembic revision --autogenerate -m "Add indexes for performance"

# Apply migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1
```

### 3.2. Migration Best Practices

1. **Always test migrations**: Test migrations on a copy of production data
2. **Backup before migration**: Always backup database before running migrations
3. **Review autogenerate**: Review autogenerated migrations before applying
4. **Index creation**: Create indexes in separate migrations for large tables
5. **Rollback plan**: Always have a rollback plan

### 3.3. Index Creation Strategy

For large tables, create indexes in separate migrations to avoid long lock times:

```python
# Migration 1: Create table
def upgrade():
    op.create_table('large_table', ...)

# Migration 2: Add indexes (run separately)
def upgrade():
    op.create_index('idx_large_table_column', 'large_table', ['column'])
```

## 4. Performance Monitoring

### 4.1. SQLite Performance

```python
# Enable query plan logging
cursor.execute("EXPLAIN QUERY PLAN SELECT ...")
```

### 4.2. PostgreSQL Performance

```sql
-- Analyze query performance
EXPLAIN ANALYZE SELECT ...;

-- Check index usage
SELECT * FROM pg_stat_user_indexes;
```

## 5. Maintenance Tasks

### 5.1. SQLite

```sql
-- Vacuum database (reclaim space)
VACUUM;

-- Analyze tables (update statistics)
ANALYZE;

-- Reindex all indexes
REINDEX;
```

### 5.2. PostgreSQL

```sql
-- Vacuum and analyze
VACUUM ANALYZE;

-- Reindex
REINDEX DATABASE database_name;
```

## 6. Index Audit Checklist

- [ ] All foreign keys have indexes
- [ ] All WHERE clause columns have indexes
- [ ] All ORDER BY columns have indexes (or are part of composite indexes)
- [ ] Composite indexes match common query patterns
- [ ] Partial indexes used where appropriate (PostgreSQL)
- [ ] Indexes are regularly maintained (VACUUM, ANALYZE)

---

**Son GÃ¼ncelleme**: 2025-12-24

