package keeper

import (
	"context"
	"crypto/sha256"
	"encoding/binary"
	"fmt"

	sdk "github.com/cosmos/cosmos-sdk/types"
	sdkmath "cosmossdk.io/math"
	stakingtypes "github.com/cosmos/cosmos-sdk/x/staking/types"

	"remes/x/remes/types"
)

// SelectProposerUsingVRF selects a proposer using Verifiable Random Function (VRF)
// based on block hash, training round ID, and validator stake
// Returns: (selected proposer address, VRF proof, error)
func (k Keeper) SelectProposerUsingVRF(
	ctx sdk.Context,
	trainingRoundID uint64,
	validators []stakingtypes.Validator,
) (string, []byte, error) {
	if len(validators) == 0 {
		return "", nil, fmt.Errorf("no validators available for proposer selection")
	}

	// 1. Create VRF input: block_hash + training_round_id
	blockHash := ctx.BlockHeader().AppHash
	roundBytes := make([]byte, 8)
	binary.BigEndian.PutUint64(roundBytes, trainingRoundID)
	
	vrfInput := append(blockHash, roundBytes...)
	
	// 2. Compute VRF hash
	vrfHash := sha256.Sum256(vrfInput)
	
	// 3. Convert hash to uint64 for modulo operation
	hashUint64 := binary.BigEndian.Uint64(vrfHash[:8])
	
	// 4. Calculate total stake for weighted selection
	totalStake := sdkmath.ZeroInt()
	stakeWeights := make([]sdkmath.Int, len(validators))
	for i, val := range validators {
		stake := val.GetTokens()
		stakeWeights[i] = stake
		totalStake = totalStake.Add(stake)
	}
	
	if totalStake.IsZero() {
		// Fallback to uniform selection if no stake
		selectedIndex := hashUint64 % uint64(len(validators))
		return validators[selectedIndex].GetOperator(), vrfHash[:], nil
	}
	
	// 5. Weighted selection based on stake
	// Use VRF hash to select a random point in [0, totalStake)
	selectedPoint := sdkmath.NewIntFromUint64(hashUint64).Mod(totalStake)
	
	// 6. Find validator whose stake range contains the selected point
	cumulativeStake := sdkmath.ZeroInt()
	for i, val := range validators {
		cumulativeStake = cumulativeStake.Add(stakeWeights[i])
		if selectedPoint.LT(cumulativeStake) {
			return val.GetOperator(), vrfHash[:], nil
		}
	}
	
	// Fallback (should not reach here)
	return validators[0].GetOperator(), vrfHash[:], nil
}

// VerifyVRFProof verifies a VRF proof for proposer selection
func (k Keeper) VerifyVRFProof(
	ctx sdk.Context,
	trainingRoundID uint64,
	proposerAddress string,
	vrfProof []byte,
) (bool, error) {
	// Reconstruct VRF input
	blockHash := ctx.BlockHeader().AppHash
	roundBytes := make([]byte, 8)
	binary.BigEndian.PutUint64(roundBytes, trainingRoundID)
	
	vrfInput := append(blockHash, roundBytes...)
	
	// Recompute VRF hash
	expectedHash := sha256.Sum256(vrfInput)
	
	// Verify proof matches
	if len(vrfProof) != len(expectedHash) {
		return false, fmt.Errorf("invalid VRF proof length")
	}
	
	for i := range vrfProof {
		if vrfProof[i] != expectedHash[i] {
			return false, fmt.Errorf("VRF proof mismatch")
		}
	}
	
	// Verify proposer was actually selected by this VRF
	// (This requires access to validator set, simplified here)
	return true, nil
}

// CommitAggregation creates a commitment for an aggregation result
// Returns: (commitment hash, error)
// salt is the random salt used in the commitment (should be generated by proposer)
func (k Keeper) CommitAggregation(
	ctx sdk.Context,
	proposer string,
	aggregatedHash string,
	merkleRoot string,
	participantIDs []uint64,
	salt string,
) (string, error) {
	// Create commitment: hash(proposer + aggregated_hash + merkle_root + participant_ids + salt)
	commitmentData := fmt.Sprintf("%s:%s:%s:%v:%s", proposer, aggregatedHash, merkleRoot, participantIDs, salt)
	commitmentHash := sha256.Sum256([]byte(commitmentData))
	
	return fmt.Sprintf("%x", commitmentHash), nil
}

// RevealAggregation reveals the aggregation result and verifies commitment
// salt is the random salt used in the commitment (revealed by proposer)
func (k Keeper) RevealAggregation(
	ctx sdk.Context,
	proposer string,
	commitmentHash string,
	aggregatedHash string,
	merkleRoot string,
	participantIDs []uint64,
	salt string,
) (bool, error) {
	// Reconstruct commitment
	expectedCommitment, err := k.CommitAggregation(ctx, proposer, aggregatedHash, merkleRoot, participantIDs, salt)
	if err != nil {
		return false, err
	}
	
	// Verify commitment matches
	return expectedCommitment == commitmentHash, nil
}

// RobustAggregation combines multiple aggregation results using median/trimmed mean
func (k Keeper) RobustAggregation(
	ctx context.Context,
	aggregationResults []types.AggregationRecord,
) (*types.AggregationRecord, error) {
	if len(aggregationResults) == 0 {
		return nil, fmt.Errorf("no aggregation results to combine")
	}
	
	if len(aggregationResults) == 1 {
		return &aggregationResults[0], nil
	}
	
	// Strategy: Use median/trimmed mean for robust combination
	// For now, return the aggregation with highest participant count
	// In production, this would implement actual median/trimmed mean of gradient values
	
	maxParticipants := uint64(0)
	bestAggregation := aggregationResults[0]
	
	for _, agg := range aggregationResults {
		participantCount := uint64(len(agg.ParticipantGradientIds))
		if participantCount > maxParticipants {
			maxParticipants = participantCount
			bestAggregation = agg
		}
	}
	
	return &bestAggregation, nil
}

// GetRevealedAggregationsForRound retrieves all revealed aggregations for a given training round
// This is used for multi-proposer robust aggregation
func (k Keeper) GetRevealedAggregationsForRound(
	ctx context.Context,
	trainingRoundID uint64,
) ([]types.AggregationRecord, error) {
	var results []types.AggregationRecord
	
	// Iterate through all aggregation records
	// Note: In production, you might want to add an index by training_round_id for efficiency
	err := k.AggregationRecords.Walk(ctx, nil, func(key uint64, value types.AggregationRecord) (stop bool, err error) {
		if value.TrainingRoundId == trainingRoundID && value.Status == "pending" {
			results = append(results, value)
		}
		return false, nil
	})
	
	if err != nil {
		return nil, fmt.Errorf("failed to retrieve aggregations: %w", err)
	}
	
	return results, nil
}

// FinalizeMultiProposerAggregation finalizes aggregation by selecting the best result from multiple proposers
// This should be called at the end of a commit-reveal period
func (k Keeper) FinalizeMultiProposerAggregation(
	ctx context.Context,
	trainingRoundID uint64,
) (*types.AggregationRecord, error) {
	// 1. Get all revealed aggregations for this training round
	aggregations, err := k.GetRevealedAggregationsForRound(ctx, trainingRoundID)
	if err != nil {
		return nil, fmt.Errorf("failed to get aggregations: %w", err)
	}
	
	if len(aggregations) == 0 {
		return nil, fmt.Errorf("no aggregations found for training round %d", trainingRoundID)
	}
	
	// 2. Use robust aggregation to select the best result
	bestAggregation, err := k.RobustAggregation(ctx, aggregations)
	if err != nil {
		return nil, fmt.Errorf("failed to perform robust aggregation: %w", err)
	}
	
	// 3. Mark other aggregations as "superseded" (optional)
	// This helps track which aggregation was selected
	for _, agg := range aggregations {
		if agg.AggregationId != bestAggregation.AggregationId {
			agg.Status = "superseded"
			if err := k.AggregationRecords.Set(ctx, agg.AggregationId, agg); err != nil {
				// Log error but don't fail
				sdk.UnwrapSDKContext(ctx).Logger().Error(fmt.Sprintf("Failed to mark aggregation %d as superseded: %v", agg.AggregationId, err))
			}
		}
	}
	
	// 4. Mark best aggregation as "finalized"
	bestAggregation.Status = "finalized"
	if err := k.AggregationRecords.Set(ctx, bestAggregation.AggregationId, *bestAggregation); err != nil {
		return nil, fmt.Errorf("failed to finalize aggregation: %w", err)
	}
	
	return bestAggregation, nil
}

